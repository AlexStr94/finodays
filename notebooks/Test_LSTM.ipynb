{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8yfpJ-PfNkj"
      },
      "source": [
        "# Импорт библиотек и загрузка данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-08-29T08:27:49.446850777Z",
          "start_time": "2023-08-29T08:27:48.925013814Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7aToFgmbcOH",
        "outputId": "1686426f-55be-4122-8b67-ff85ae0e1bc5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "import spacy\n",
        "from langdetect import detect\n",
        "import pickle\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import load_model\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4odT5RZehMm",
        "outputId": "7e66ef34-ca29-4cec-b504-3f710d275b4b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "\n",
        "nlp_eng = spacy.load('en_core_web_sm', disable=['ner', 'parser'])\n",
        "nlp_rus = spacy.load('ru_core_news_sm', disable=['ner', 'parser'])\n",
        "\n",
        "stop_words_rus = stopwords.words('russian')\n",
        "stop_words_eng = stopwords.words('english')\n",
        "stop_words = stop_words_rus+stop_words_eng+['шт', 'каждый день', 'каждый', 'день', 'красная цена', 'красная', 'цена', 'верный', 'дикси', 'моя', 'моя цена', 'окей','то, что надо!', 'smart','spar', 'ашан']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aI1BQRZpfNkk"
      },
      "source": [
        "## Загрузка токенизатора и модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQHAHGuEfNkk"
      },
      "outputs": [],
      "source": [
        "tf.config.run_functions_eagerly(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kEFEzIyHV2Pi"
      },
      "outputs": [],
      "source": [
        "with open('LSTM_tokenizer.pkl', 'rb') as f:\n",
        "    tokenizer = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-SsZDI5PV2Pi"
      },
      "outputs": [],
      "source": [
        "loaded_model = load_model(\"LSTM_model.h5\", custom_objects={'Addons>F1Score': tfa.metrics.F1Score})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAwGHsEYfNkl"
      },
      "source": [
        "# Создание функций"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmGyTMJtfNkl"
      },
      "source": [
        "## Загрузка данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_yB4xlEkZcM"
      },
      "outputs": [],
      "source": [
        "def get_fake_transactions(df):\n",
        "\n",
        "    return df[df['client'] == 'Шариков Алексей Юрьевич'].to_dict(orient='records')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkVcG6DxfNkl"
      },
      "source": [
        "## Обработка текстов покупок"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ysfBRPcAV2Pj"
      },
      "outputs": [],
      "source": [
        "def preprocess_sentences(sentences, tokenizer, max_length):\n",
        "    sequences = tokenizer.texts_to_sequences(sentences)\n",
        "    padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post', truncating='post')\n",
        "    return padded_sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybiFygApfNkl"
      },
      "source": [
        "## Подготовка текста для модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BYqwnca5eUiM"
      },
      "outputs": [],
      "source": [
        " def tokenize_text(products):\n",
        "\n",
        "        all_sentence = []\n",
        "\n",
        "        for value in products:\n",
        "            try:\n",
        "                lang = detect(value)\n",
        "\n",
        "                if lang == 'en':\n",
        "                    doc = nlp_eng(value)\n",
        "                    lemmas = [token.lemma_ for token in doc if token.is_alpha and token.text not in punctuation and token.text.lower() not in stop_words]\n",
        "                    cleaned_sentence = \" \".join(lemmas)\n",
        "                    all_sentence.append(cleaned_sentence)\n",
        "                else:\n",
        "                    doc = nlp_rus(value)\n",
        "                    lemmas = [token.lemma_ for token in doc if token.is_alpha and token.text not in punctuation and token.text.lower() not in stop_words]\n",
        "                    cleaned_sentence = \" \".join(lemmas)\n",
        "                    all_sentence.append(cleaned_sentence)\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing value: {value}\")\n",
        "                print(f\"Error message: {str(e)}\")\n",
        "\n",
        "        padded_sequences = preprocess_sentences(all_sentence, tokenizer, 29)\n",
        "\n",
        "        return padded_sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mve8_LwpfNkm"
      },
      "source": [
        "# Подготовка и обзор данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XY_tbBQvfNkm"
      },
      "outputs": [],
      "source": [
        "df2 = pd.read_excel('final_df.xlsx', sheet_name='Sheet1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-08-29T08:28:45.539575351Z",
          "start_time": "2023-08-29T08:28:44.028178721Z"
        },
        "id": "8htZALpFbcON"
      },
      "outputs": [],
      "source": [
        "transactions = get_fake_transactions(df2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NOOLuM5fNkm"
      },
      "source": [
        "Посмотрим на названия продуктов и их категории"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMQoldO9fNkm"
      },
      "outputs": [],
      "source": [
        "product_names = [transaction['sale'] for transaction in transactions]\n",
        "true_topics = [transaction['topic'] for transaction in transactions]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lK5jPYwCfNkm",
        "outputId": "dc6fdb9c-d6e5-42fa-a2ae-420bba56775f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Свеча зажигания ngk 7422 bpr5es 1 шт.',\n",
              " 'Змз вкладыши коренные змз 2101 0.5 21010-1000102-22',\n",
              " 'Теплообменник vag 7h0 819 032',\n",
              " 'Dennerle humin elixier средство для подготовки водопроводной воды, 500 мл',\n",
              " 'Dennerle carbo elixier bio удобрение для растений, 500 мл',\n",
              " 'Жевательный мармелад фру-фру трубочка тропические фрукты 35...',\n",
              " 'Эскалоп из индейки пава-пава охлажденный 600 г',\n",
              " 'Пряники полет шоколадные 250 г',\n",
              " 'Биойогурт актибио с черносливом 2,9% 130 г',\n",
              " 'Жевательная резинка orbit сочный арбуз без сахара 13,6 г',\n",
              " 'Колбаса варено-копченая ближние горки сервелат австрийский...',\n",
              " 'Батончики рот фронт с вафельной крошкой',\n",
              " 'Плитка milka молочная 85 г',\n",
              " 'Мармелад fruittella yo!rms жевательный 138 г',\n",
              " 'Творог зерненый савушкин с клубникой 5% бзмж 130 г',\n",
              " 'Кондиционер для детского белья vernel 1,82 л',\n",
              " 'Гель glorix med 7 в 1 дезинфицирующий 750 мл',\n",
              " 'Хозяйственное мыло аист концентрированное с глицерином 150 г',\n",
              " 'Ватные палочки ola! silk sense 200 шт',\n",
              " 'Порошок заводъ братьевъ крестовниковыхъ традиции качества...',\n",
              " 'Насадка для швабры плоский моп actuel',\n",
              " 'Установка для подачи со? dennerle bio complete set, 120 л',\n",
              " 'Грунт dennerle nano gravel, природный белый, 2кг',\n",
              " 'Dennerle nutribasis 6in1 - грунтовая подкормка для аквариумных растений, пакет 9,6 кг для аквариумов',\n",
              " 'Листья миндаля dennerle catappa leaves 8шт',\n",
              " 'Арахис мааг жареный со вкусом лука и сметаны 60 г',\n",
              " 'Майонезный соус махеевъ сливочно-чесночный 25% 200 мл',\n",
              " 'Чипсы картофельные lorenz naturals пармезан 100 г',\n",
              " 'Кофе poetti daily arabica в зернах 1 кг',\n",
              " 'Тараллини nina farina классические 180 г']"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "product_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X215GcIVfNkm",
        "outputId": "8821c2ed-d0f7-492c-c432-b18dbfa82dbb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['автозапчасти',\n",
              " 'автозапчасти',\n",
              " 'автозапчасти',\n",
              " 'аквариум',\n",
              " 'аквариум',\n",
              " 'продукты питания',\n",
              " 'продукты питания',\n",
              " 'продукты питания',\n",
              " 'продукты питания',\n",
              " 'продукты питания',\n",
              " 'продукты питания',\n",
              " 'продукты питания',\n",
              " 'продукты питания',\n",
              " 'продукты питания',\n",
              " 'продукты питания',\n",
              " 'уборка',\n",
              " 'уборка',\n",
              " 'уборка',\n",
              " 'уборка',\n",
              " 'уборка',\n",
              " 'уборка',\n",
              " 'аквариум',\n",
              " 'аквариум',\n",
              " 'аквариум',\n",
              " 'аквариум',\n",
              " 'закуски и приправы',\n",
              " 'закуски и приправы',\n",
              " 'закуски и приправы',\n",
              " 'напитки',\n",
              " 'напитки']"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "true_topics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gz8P2nHPfNkm"
      },
      "source": [
        "Обработка текстов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12VSaueChysw"
      },
      "outputs": [],
      "source": [
        "tokens = tokenize_text(product_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBh6pY6dfNkm"
      },
      "source": [
        "# Предсказание категорий и сравнение с оригиналом"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "tkTrE6owV2Pk",
        "outputId": "7043dcd6-dbc5-4d1a-a63b-ab88e60285f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 90ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:265: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "predictions = np.argmax(loaded_model.predict(tokens), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8W8yxnBX31NM",
        "outputId": "4c8d4c0c-7d3f-442b-c4ea-fa17153ea654"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 40ms/step\n"
          ]
        }
      ],
      "source": [
        "predictions = np.argmax(loaded_model.predict(tokens), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJXN95YQi01w",
        "outputId": "75de52ae-c774-4eb2-dfea-454a9d35507f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 1, 0, 5, 5, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 7, 7, 7, 7, 7, 7, 5,\n",
              "       5, 5, 5, 4, 4, 4, 2, 3], dtype=int64)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LXA0HTO8mf7-"
      },
      "outputs": [],
      "source": [
        "dictionary = { \"topic\": ['автозапчасти', 'видеоигры', 'напитки', 'продукты питания', 'закуски и приправы', 'аквариум', 'одежда', 'уборка', 'электроника', 'образование'], \"label\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] }\n",
        "topics=[]\n",
        "for index in range(len(predictions)):\n",
        "  label = predictions[index].item()\n",
        "  topic = dictionary['topic'][dictionary['label'].index(label)]\n",
        "  topics.append(topic)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iuRkKZS1o5LA",
        "outputId": "fc68ab32-7f2e-49d2-88a0-9b589dc15cf4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['автозапчасти',\n",
              " 'видеоигры',\n",
              " 'автозапчасти',\n",
              " 'аквариум',\n",
              " 'аквариум',\n",
              " 'продукты питания',\n",
              " 'продукты питания',\n",
              " 'продукты питания',\n",
              " 'продукты питания',\n",
              " 'продукты питания',\n",
              " 'продукты питания',\n",
              " 'продукты питания',\n",
              " 'продукты питания',\n",
              " 'продукты питания',\n",
              " 'продукты питания',\n",
              " 'уборка',\n",
              " 'уборка',\n",
              " 'уборка',\n",
              " 'уборка',\n",
              " 'уборка',\n",
              " 'уборка',\n",
              " 'аквариум',\n",
              " 'аквариум',\n",
              " 'аквариум',\n",
              " 'аквариум',\n",
              " 'закуски и приправы',\n",
              " 'закуски и приправы',\n",
              " 'закуски и приправы',\n",
              " 'напитки',\n",
              " 'продукты питания']"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "topics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Mh4P8m9fNkn"
      },
      "source": [
        "Посмотрим на точность"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Rnhn8nHfNkn",
        "outputId": "8849b68f-7bcb-4ff6-a95f-70c6689457ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Точность прогноза: 93.33%\n"
          ]
        }
      ],
      "source": [
        "correct_predictions = sum(predicted == true for predicted, true in zip(topics, true_topics))\n",
        "print(f'Точность прогноза: {((correct_predictions / len(true_topics)) * 100):.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcEx-vcXfNkn"
      },
      "source": [
        "Очень высокая точность, свыше 93 %"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3rWKR7lfNko"
      },
      "source": [
        "Посмотрим, где конкретно ошиблась модель"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7mZWm3XWfNko"
      },
      "outputs": [],
      "source": [
        "incorrect_indices = [i for i, (predicted, true) in enumerate(zip(topics, true_topics)) if predicted != true]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u0HcA-A7fNko",
        "outputId": "ea1b6fcf-38a3-4947-feb0-9fb82e9aea3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Продукт: Змз вкладыши коренные змз 2101 0.5 21010-1000102-22\n",
            "Истинная метка: автозапчасти\n",
            "Предсказанная метка: видеоигры\n",
            "--------------\n",
            "Продукт: Тараллини nina farina классические 180 г\n",
            "Истинная метка: напитки\n",
            "Предсказанная метка: продукты питания\n",
            "--------------\n"
          ]
        }
      ],
      "source": [
        "for i in incorrect_indices:\n",
        "    print(f\"Продукт: {product_names[i]}\")\n",
        "    print(f\"Истинная метка: {true_topics[i]}\")\n",
        "    print(f\"Предсказанная метка: {topics[i]}\")\n",
        "    print(\"--------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tjf5iCgsfNkr"
      },
      "source": [
        "Как видим, одна \"ошибка\", это и вовсе исправление ошибки из разметки!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}